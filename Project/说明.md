**Preprocessing & Visualization & Clustering** の分析

---

# Data Preprocessing
这里做的工作包括：
1. 处理缺失信息
  我们使用的方法包括：
  - 对于缺失值在35%以上的特征一律删除（缺失值过多，难以填充）
  - 对于缺失值在35%以下的特征采取以下两种措施之一：
    - 若为数值变量，我们采用K Nearest Neighbor方法，考虑其附近的13个数据点，并取加权平均（权值与两点间的距离的倒数）
    - 若为类别变量，我们用众数填补
  - 同时，若有缺失信息，我们新增一列，意义为体现该列数据是否在原数据集中缺失（因为在官方描述中一些值为因故缺失）

2. 异常值识别

  我们识别的异常值包括：
  - 对于数值变量，采用IQR方法，异常范围定义为2.5倍的IQR以外的数据点
  - 对于类别变量，统计出现频次，异常范围定义为频次在0.5%以下

  由于我们预测的数据与生存率有关，一般情形下我们认为死亡必然与异常值有一定联系，因而我们对于异常值的处理保留一定的空间，即：

  **对于每一个数据点，若有不超过个特征被识别为异常值，我们并不将该数据点作为异常值删除；若有大于等于两个特征被识别为异常值，我们将该数据点当作异常值并删除**

3. 特征工程

我们进行了如下的处理：
- 对于年龄分类，以45， 60， 79将年龄分为小登，中登，老登，太老登
- 对于SUPPORT2模型对于存活率的预测，通过两个月和六个月的存活率，构造一个风险率为前两个月的存活率的平方除以六个月的存活率，最后再通过sigmoid函数将其转化为0-1之间的数，预测病人的风险
- 由于physician(医生)也有自己关于存活率的估值，我们同样计算一个类似的风险，并且分别将模型的预测值（2个月，6个月）与医生的作除法，体现二者预测上的差距
- 对于缴费，由于这类分布通常会右拖尾（更少的人付更多的钱），我们采用取对数的策略，并将其平移到非负数区间内并乘以倍数5以保证数据均匀分布，非负且一定程度上稀疏
- 对于若干身体指标，我们基于指标情况预测其是否有一定的征兆，如PH值小于7.35即为酸性，体温高于38.0即为发烧，具体为：
```python
data['low_BP'] = data['meanbp'] <= 65
data['high_HR'] = data['hrt'] >= 100
data['high_resp'] = data['resp'] >= 30
data['high_temp'] = data['temp'] >= 38.0
data['low_temp'] = data['temp'] <= 36.0
# pafi is a measure of the severity of illness, often used in critical care settings.
data['ARDS_severity'] = data['pafi'].apply(lambda x: 'Normal' if x >=300 else ('Mild' if x >= 200 else ('Moderate' if x >= 100 else 'Severe')))
# arterial ph
data['acidosis'] = data['ph'] < 7.35
data['alkalosis'] = data['ph'] > 7.45
# Bilirubin is a measure of liver function, often used in critical care settings.
data['bili_high'] = data['bili'] > 2.0
# Creatinine is a measure of kidney function, often used in critical care settings.
data['creatinine_high'] = data['crea'] > 2
```
- 对于adl分数，我们检测该分数是否大于等于4。这与sfdm2有一定关联，其中一类即"adl>=4 (>=5 if sur)"。

4. 特征选取

对数据排除存在的三列target并归一化和编码以后，我们以death为目标预测列，保留与其强相关的特征。具体方法为结合两种feature selection方法：
1. logistic regression+一范数，其中惩罚项常数的倒数C为0.01，该方法提取19个特征列
2. gradient boosting预测并返回feature importance，其中每棵树最大深度为6，预测器设为100，该方法提取25个特征列

通过合并二者，得到7012行\(\times\)36列。其中dzclass并不在其中，但是我们将通过Data Visualization来说明加入dzclass的有效性。同时，注意到dzclass的feature importance与logistic regression的惩罚项相关，且惩罚程度若再调得更小一点(C=0.05)则dzclass被包含在内。

5. 其它工作

再进一步检查缺失值后，我们将剩余的类别变量进行编码，其中对于收入,sfdm2两个变量采用排序编码，其余采用独热编码，并删去原有数据列。通过该方法，得到90列。

# Data Visualization

我们研究数据点在特征空间内关于dzclass的分布情况。由图可知分布在二维上可以被清晰的划分，在三维视图上存在一定的可识别度。这说明该数据集关于该特征是可分的，且存在一定的线性可分性。同时，通过与death和hospdead在类似图形上的分布我们可以看到死亡情况与dzclass在一定程度上相关（同一个参数画的图，只是因为标签不同导致颜色不同，因而可比），如一些疾病类中死亡率更低。因而尽管feature selection没有包含该特征，我们也有充分的理由将其纳入最终的特征列。

# Clustering Analysis

我们探索各种方法对于聚类的可行性以及数据的处理问题，即：KMeans, DBSCAN，和GMM对于raw data和scaled data（standardize过后的结果）上的预处理能力。

以下为最佳模型：

（raw data）
- KMeans with 5 clusters: Silhouette Score = 0.3660
- KMeans with 5 clusters: Calinski-Harabasz Score = 4368.6178
- KMeans with 5 clusters: Davies-Bouldin Score = 0.9249
- KMeans with 5 clusters: Adjusted Rand Index = -0.0043
- KMeans with 5 clusters: Normalized Mutual Information = 0.0111
- DBSCAN with eps=60: Silhouette Score = 0.6813
- DBSCAN with eps=60: Calinski-Harabasz Score = 581.2619
- DBSCAN with eps=60: Davies-Bouldin Score = 2.4304
- DBSCAN with eps=60: ARI = -0.0167
- DBSCAN with eps=60: NMI = 0.0108
- GMM with 2 clusters: Silhouette Score = 0.1505
- GMM with 2 clusters: Calinski-Harabasz Score = 308.1016
- GMM with 2 clusters: Davies-Bouldin Score = 3.8006
- GMM with 2 clusters: ARI = -0.0237
- GMM with 2 clusters: NMI = 0.0553

（scaled data）
- KMeans with 5 clusters: Silhouette Score = 0.1173
- KMeans with 5 clusters: Calinski-Harabasz Score = 552.0029
- KMeans with 5 clusters: Davies-Bouldin Score = 2.4960
- KMeans with 5 clusters: Adjusted Rand Index = 0.0551
- KMeans with 5 clusters: Normalized Mutual Information = 0.1221
- DBSCAN with eps=12.4800: Silhouette Score = 0.3768
- DBSCAN with eps=12.4800: Calinski-Harabasz Score = 103.7204
- DBSCAN with eps=12.4800: Davies-Bouldin Score = 0.9305
- DBSCAN with eps=12.4800: ARI = 0.0001
- DBSCAN with eps=12.4800: NMI = 0.0000
- GMM with 2 clusters: Silhouette Score = 0.0992
- GMM with 2 clusters: Calinski-Harabasz Score = 692.1909
- GMM with 2 clusters: Davies-Bouldin Score = 3.0637
- GMM with 2 clusters: ARI = 0.0148
- GMM with 2 clusters: NMI = 0.0066